---
layout: post
title:  "데이터 중심 애플리케이션 설계 03장"
date:   2022-03-08
comments: true
project: true
excerpt: "데이터 중심 애플리케이션 설계 03장"
categories: book
---

## 저장소와 검색

이번 장에서는 익숙한 데이터베이스 종류인 관계형 데이터베이서와 NoSQL라 불리는 데이터베이스에 사용되는 저장소 엔진에 대해 알아본다.
로그 구조(log-structured) 계열 저장소 엔진 (B-tree)과 페이지 지향(page-oriented) 계열 저장소 엔진에 대해서도 알아본다.

## 데이터베이스를 강력하게 만드는 데이터 구조

로그 : 주로 애플리케이션에서 무슨 일이 일어났는지를 기술한 텍스트를 의미하지만, 여기서는 일반적인 의미로 연속된 추가 전용(append-only) 레코드로 쓰인다.
기본적인 저장소 형식은 csv 파일과 유사한 key-value 쌍의 텍스트 파일이라고 볼 수 있다.
실제 데이터베이스도 내부적으로 이런 로그 파일을 사용한다.

bash를 이용한 간단한 구현

```bash
#!/bin/bash

db_set () {
  echo "$1,$2" >> database
}

db_get () {
  grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```

한편 db_get 함수는 데이터 베이스에서 검색을 위해 O(n)의 시간이 걸린다. 이를 해결하기 위해서 색인이 필요하다.


기본적인 저장소 형식은 csv 파일과 유사한 key-value 쌍의 텍스트 파일이라고 볼 수 있다.

색인의 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것이다.
모든 색인은 쓰기 속도를 떨어뜨린다. 애플리케이션 개발자나 데이터베이스 관리자가 애플리케이션의 전형적인 질의 패턴에 대한 지식을 활요해 수동으로 색인을 선택해야한다.

### 해시 색인

기본적인 구조 해시 맵을 사용해 데이터 파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽는다.
ex.) 비트캐스크는 해시 맵을 RAM에 저장하여 고성능 읽기 쓰기를 보장한다. => 키의 값이 자주 갱신되는 상황에 매우 적합

한편 파일에 항상 추가만 한다면 디스크 공간이 부족해진다. 이에 대한 해결책으로 세그먼트로 로그를 나누는 방식이 있다.
한개의 세그먼트 파일이 다 쓰여지면 컴팩션 과정을 통해 세그먼트에서 각  키의 최신 값만을 유지한다.
각 세그면트는 키를 파일 오프셋에 매핑한 자체 인메모리 해시 테이블을 갖는다. 키의 값을 찾으려면 최신 세그먼트 해시 맵을 먼저 확인하고 이후 두번째 최신 세그먼트 등을 확인한다.

이를 구현하기 위해서는 다음과 같은 사항들이 고려되어야 한다.

- 파일 형식: CSV는 로그에 가장 적합한 형식이 아니다. 바이너리 형식이 더 빠르고 간단하다.
- 레코드 삭제 : 키와 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드(tombstone)를 추가해야한다. 
- 고장(Crash) 복구 : 데이터베이스가 재시작되면 인메모리 해시 맵은 손실된다. 비트캐스크는 각 세그먼트 해시 맵을 메모리로 조금 더 빠르게 로딩할 수 있게 스냅샷을 디스크에 저장해 복구 속도를 높인다.
- 부분적으로 레코드 쓰기 : 데이터베이스는 로그에 레코드를 추가하는 도중에도 죽을 수 있다. 비트캐스크 파일은 체크섬을 포함하고 있어 로그의 손상된 부분을 탐지해 무시할 수 있다.
- 동시성 제어 : 쓰기를 엄격하게 순차적으로 로그에 추가할 때 일반적인 구현 방법은 하나의 쓰기 스레드만 사용하는 것이다. 데이터 파일 세그먼트는 추가 전용이거나 불변이므로 다중 스레드로 동시에 읽기를 할 수 있다.

추가 전용 로그의 장점

- 추가와 세그먼트 병합은 순차적인 쓰기 작업이기 때문에 보통 무작위 쓰기보다 훨씬 빠르다. 특히 HDD에서 그렇다. 
- 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구는 훨씬 간단하다.
- 오래된 세그먼트 병합은 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있다.

하지만 해시 테이블 색인 또한 제한 사항이 있다.

- 해시 테이블은 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다. 원칙적으로는 디스크에 해시 맵을 유지 할 수 있지만 좋은 성능을 기대하기 어렵다.
- 해시 테이블은 범위 질의에 효율적이지 않다. 해시 맵에서 모든 개별 키를 조회해야 한다.

### SS테이블과 LSM 트리

SS table (Sorted String Table)은 DB의 key-value 쌍을 키로 정렬한 것이다. 병합된 세그먼트 파일에 key는 중복이 없다.
SS table은 해시 색인을 가진 로그 세그먼트보다 볓가지 큰 장점이 있다.

- 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적이다. mergesort와 유사한 방식으로 세그먼트의 병합이 이뤄진다.
- 파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다.

#### SS테이블 생성과 유지

저장소 엔진을 다음과 같이 만들 수 있다.
- 쓰기가 들어오면 인메모리 균형 트리(balanced tree) 데이터 구조(예를 들어 레드 블랙 트리)에 추가한다. 이 인메모리 트리는 멤테이블(memtable)이라고도 한다.
- 맴테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS테이블 파일로 디스크 기록한다. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있기 때문에 효율적으로 수행할 수 있다. 새로운 SS테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다. SS 테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다.
- 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야 한다. 그 다음 디스크 상의 가장 최신 세그먼트에서 찾는다. 그리고 2번째 3번째 ... 순의 세그먼트에서 찾는다.
- 가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 수행한다. 이 과정은 백그라운드에서 수행된다.
한편 데이터베이스가 고장 났을 때 아직 디스크에 기록되지 않은 사항이 날아 갈 수 있으므로 이를 위해 분리된 로그를 디스크 상에 유지한다.

#### SS테이블에서  LSM 트리 만들기

LSM 트리(Log-Structured Merge-Tree) : 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.

#### 성능 최적화

LSM 트리 알고리즘은 데이터베이스에 존재하지 않는 키를 찾는 경우 느릴 수 있다. 이런 종류의 접근을 최적화하기 위해 저장소 엔진은 보통 Bloom filter를 추가적으로 사용한다.


SS 테이블을 압축하고 병합하는 순서와 시기를 결정하는 다양한 전략
- size-tiered : 상대적으로 좀더 새롭고 작은 SS테이블을 상대적으로 오래됐고 큰 SS테이블에 연이어 병합
- leveled compaction  : 키 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 "레벨"로 이동하기 때문에 컴팩션을 점진적으로 진행해 디스크 공간을 덜 사용한다.

### B 트리

가장 널리 사용되는 색인 구조

B 트리는 전통적으로 4KB 크기의 고정 크기 블록이나 페이지로 나누고 한번에 하나의 페이지에 읽기 또는 쓰기를 한다.
디스크가 고정 크기 블록으로 배열되기 때문에 이런 설계는 근본적으로 하드웨어와 조금 더 밀접한 관련이 있다.

- 한페이지가 B트리의 root로 지정되고, 키를 찾으려면 이 root에서 시작한다. 각 하위 페이지는 키가 계속 이어지는 범위를 담당하고 참조 사이의 키는 해당 범위 경계가 어디인지 나타낸다.
- 최종적으로는 개별 키를 포함하는 페이지(leaf page)에 도달한다.  이 페이지는 각 키의 값을 포함하거나 값을 찾을 수 있는 페이지의 참조를 포함한다.

B 트리의 한페이지에서 하위 페이지를 참조하는 수를 분기 계수 (branching factor)라고 부른다.
값을 갱신할 때는 값을 찾아 기록하고, 값을 추가할 때는 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가한다. 새로운 키를 수용할 페이지에 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 갱신한다.  이 알고리즘은 트리가 계속 균형을 유지하는 것을 보장하며 n 개의 키를 가진 B tree는 깊이가 항상 O(log n)이다.

#### 신뢰할 수 있는 B 트리 만들기

B 트리의 기본적인 쓰기 동작은 새로운 데이터를 디스크 상의 페이지에 덮어쓴다. 이 동작은 덮어쓰기가 페이지의 위치를 변경하지 않는다고 가정한다.

데이터베이스가 고장 상황에서 스스로 복구할 수 있게 만들려면 일반적으로 디스크 상에 쓰기 전 로그(write-ahead log, WAL)라고 하는 데이터 구조를 추가해 B 트리를 구현한다.
쓰기 전 로그는 트리 페이지에 변경된 내용을 적용하기 전에 모든 B 트리의 변경 사항을 기록하는 추가 전용 파일이다. 이 로그는 데이터베이스가 고장 이후 복구될 때 일관성 있는 상태로 B 트리를 다시 복원하는 데 사용한다.

동시성 제어는 보통 래치(latch)로 트리의 데이터 구조를 보호한다.
=> 이러한 면에서는 로그 구조화 접근 방식이 훨씬 간단하다. 유입 질의의 간섭 없이 백그라운드에서 모든 병합을 수행하고 이따금 원자적으로 새로운 세그몬트를 이전 세그먼트로 바꾸기 때문이다.

#### B 트리 최적화

- 페이지 덮어 쓰기와 고장 복구를 위한 WAL 유지 대신 (LMDB 같은) 일부 데이터베이스는 쓰기 시 복사 방식 (copy-on-write scheme)을 사용한다. 변경된 페이지는 다른 위치에 기록하고 트리에 상위 페이지의  새로운 버전을 만들어 새로운 위치를 가리키게 한다.
- 페이지에 전체 키를 저장하는 게 아니라 키를 축약해 쓰면 공간을 절약할 수 있다. 특히 트리 내부 페이지에서 키가 키 범위 사이의 경계 역할을 하는 데 충분한 정보만 제공하면 된다. 페이지 하나에 키를 더 많이 채우면 트리는 더 높은 분기 계수를 얻는다. 그러면 트리 깊이 수준을 낮출 수 있다.
- 일반적으로 페이지는 디스크 상 어디에나 위치할 수 있다. 키 범위가 가까운 페이지들이 디스크 상에 가까이 있어야 할 필요가 없기 때문이다. 질의가 정렬된 순서로 키 범위의 상당 부분을 스캔해야 한다면 모든 페이지에 대해 디스크 찾기가 필요하기 때문에 페이지 단위 배치는 비효율적이다. 따라서 많은 B 트리 구현에서 리프 페이지를 디스크 상에 연속된 순서로 서로 나타나게끔 트리를 배치하려 시도한다. 하지만 트리가 커지면 순서를 유지하기가 어렵다. 반대로 LSM 트리는 병합하는 과정에서 저장소의 큰 세그먼트를 한 번에 다시 쓰기 때문에 디스크에서 연속된 키를 서로 가깝게 유지하기가 더 쉽다.
- 트리에 포인터를 추가한다. 예를 들어 각 리프 페이지가 양쪽 형제 페이지에 대한 참조를 가지면 상위 페이지로 다시 이동하지 않아도 순서대로 키를 스캔할 수 있다.
- 프랙탈 트리(fractal tree) 같은 B 트리 변형은 디스크 찾기를 줄이기 위해 로그 구조화 개념을 일부 빌렸다.

### B 트리와 LSM 트리 비교

#### LSM 트리의 장점

B 트리 색인은 모든 데이터 조각을 최소한 두번 기록해야한다. 쓰기 전 로그 한번과 트리 페이지에 한번. 해당 페이지 내 몇 바이트만 바뀌어도 한 번에 전체 페이지를 기록해야하는 오버헤드도 있다.
로그 구조화 색인 또한 SS테이블의 반복된 컴팩션과 병합으로 인해 여러 번 데이터를 다시 쓴다.

쓰기 증폭 (write amplification) : 데이터베이스에 쓰기 한 번이 데이터베이스 수명 동안 디스크에 여러 번의 쓰기를 야기하는 효과

- 트리에서 여러 페이지를 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS테이블을 쓰므로 LSM 트리가 상대적으로 쓰기 증폭이 더 낮다.
- LSM 트리는 압축률이 더 좋다. B 트리는 파편화로 인해 사용하지 않는 공간이 생긴다.

#### LSM 트리의 단점

- 컴팩션 과정이 때로는 진행 중인 읽기와 쓰기의 성능에 영향을 준다. 이에 비해 B트리의 성능은 로그 구조화 저장소 엔진보다 예측하기 쉽다.
- 데이터베이스가 점점 커질수록 컴팩션을 위해 더 많은 디스크 대역폭이 필요하다.
- B트리의 장점은 키가 색인의 한곳에만 정확하게 존재한다는 점이다. 이로 인해 B트리에서는 transactional isolation 구현을 직접 트리에 직접 잠금을 포함시킴으로써 이뤄진다. 이 내용은 7장에서 더 자세히 다룬다

### 기타 색인 구조

키-값 색인의 대표적인 예는 관계형 모델의 기본키(primary key) 색인이다. 관계형 테이블에서는 하나의 row 문서 데이터베이스에서는 하나의 문서, 그래프 데이터베이스에서는 하나의 정점을 식별하는데 사용.
보조 색인(secondary index)을 사용하는 방식도 매우 일반적이다. => 효율적으로 조인을 수행하는데 결정적인 역할을 한다.

### 색인 안에 값 저장하기

키 : 질의가 검색하는 대상
값 : 다음 두 가지 중 하나
- 질문의 실제 로우
- 다른 곳에 저장된 로우를 가리키는 참조 (heap file을 가리킴)

힙 파일 접근 방식은 키를 변경하지 않고 값을 갱신할 때 효율적이다.
색인 에서 힘 파일로 다시 이동하는 일은 읽기 성능에 불이익이 너무 많기 때문에 색인안에 바로 색인된 로우를 저장하는 경우도 있다 => 클러스터드 색인(clustered index)
ex.) mysql의 InnoDB 에서 테이블의 기본키가 언제나 클러스터드 색인이고 보조 색인은 기본키를 참조한다.

커버링 색인(covering index) 혹은 포괄열이 있는 색인(index with included column) : 색인안에 일부 column만 저장하는 방식

### 다중 칼럼 색인

결합 색인(concatenated index) : 하나의 칼럼에 다른 칼럼을 추가하는 방식으로 하나의 키에 여러 필드를 단순히 결합한다.
B트리나 LSM 트리 색인의 경우 2차원 질의(ex. gps)에 적합하지 않다. 이를 해결 하는 방법으로는 두 가지 방법이 있다.
- 이차원 위치를 공간 채움 곡선을 이용해 단일 숫자로 변환하여 사용
- R 트리와 같은 전문 공간 색인을 사용한다.

### 전문 검색과 퍼지 색인

애매모호한(fuzzy) 질의에는 다른 기술이 필요하다.

ex.) 루씬은 문서나 질의의 오타에 대처하기 위해 특정 편집 거리(edit distance)내 단어를 검색할 수 있다.


루씬 내부에서 인메모리 색인으로 trie와 유사한 오토마톤을 사용. levenshtein automaton과 유사 (특정 편집 거리 내에서 효율적인 단어 검색을 제공)

### 모든 것을 메모리에 보관

인메모리 데이터베이스 : 디스크를 사용하는 대신 인메모리를 주로 사용 => 인메모리 데이터베이스가 재시작 되는 경우 특수 하드웨어를 사용하지 않는다면 디스크나 네트워크를 통해 복제본에서 다시 적재해야함.

ex.) VoltDB, MemSQL, Oracle TimesTen

## 트랜잭션 처리나 분석?

- commercial transaction :  판매, 공급 업체에 발주, 직원 급여 지불등과 같은 비즈니스 데이터 처리
- online transaction processing(OLTP) :  일반적인 애플리케이션에서 사용하는 사용자 입력 기반의 대화식 트랜잭션

요즘에는 data analytic에 데이터베이스를 사용하기 시작. 분석 질의는 많은 수의 레코드를 스캔해 레코드당 일부 칼럼만 읽어 집계 통계를 계산해야한다.
이런 데이터베이스 사용패턴을 트랜잭션 처리와 구별하기 위해 온라인 분석 처리 (online analytic processing, OLAP)라고 부른다.

| 특성           | 트랙잭션 처리 시스템(OLTP)                       | 분석 시스템(OLAP)                  |
|----------------|--------------------------------------------------|------------------------------------|
| 주요 읽기 패턴 | 질의당 적은 수의 레코드, 키 기준으로 가져옴      | 많은 레코드에 대한 집계            |
| 주요 쓰기 패턴 | 임의 접근, 사용자 입력을 낮은 지연 시간으로 기록 | 대규모 불러오기 또는 이벤트 스트림 |
| 주요 사용처    | 웹 애플리케이션을 통한 최종 사용자/소비자        | 의사결정 지원을 위한 내부 분석가   |
| 데이터 표현    | 데이터의 최신 상태(현재 시점)                    | 시간이 지나며 일어난 이벤트 이력   |
| 데이터셋 크기  | 기가바이트에서 테라바이트                        | 테라바이트에서 페타바이트          |

SQL은 OLAP유형에서도 잘 동작하지만 분석을 위한 데이터베이스를 따로 두는 경항을 보임 => 데이터 웨어하우스(data warehouse)

### 데이터 웨어하우징

OLTP 높은 가용성과 낮은 지연 시간의 트랜잭션 처리를 기대한다. 즉석 분석 질의는 비용이 비싸기 때문에 트랜잭션의 성능을 저하시킬 가능성이 있다.

데이터웨어하우스는 OLTP 작업에 영향을 주지 않고 마음껏 질의가 가능하다. => OLTP의 읽기 전용 복사본
중간중간 데이터 웨어 하우스로 데이터를 가져오는 과정을 ETL (Extract-Transform-Load)라고 부른다.

### OLTP 데이터베이스와 데이터 웨어하우스의 차이점

일반적으로 SQL은 분석질의에 적합하기 때문에 데이터 웨어하우스 모델도 관계형 데이터 베이스를 사용한다. SQL 생성하고 결과를 시각화하고 분석가가 데이터를 탐색할 수 있게 해주는 여러 그래픽 분석 도구가 있다.
한편 표면적으로는 데이터 웨어하우스와 관계형 OLTP 데이터 베이스가 비슷해보이지만 내부 시스템은 완전히 다르다. SQL 질의 인터페이스를 지원하는 공통점은 있다.

ex.) Teradata, Vertica, SAP 하나, ParAccel => 상용, SQL-on-Hadoop => 오픈소스

##### 분석용 스키마: 별모양 스키마와 눈꽃송이 모양 스키마

star schema 혹은 dimensional modeling이라고도 한다.

일련의 개별 이벤트를 담은 사실 테이블 (fact table)이 있고 각각의 컬럼은 dimensional table이라고 불리는 다른 테이블을 가리키는 외래키 참조다.
눈꽃송이 모양 스키마(snowflake schema)는 star schema에서 dimensional table이 외래키 참조를 가져 차원이 하위 차원으로 더 세분화되는 schema이다.
더 정규화된 schema이지만 작업이 더 어렵다는 이유로 star schema가 선호된다.

### 칼럼 지향 저장소

dimensional table은 보통 비교적 작지만(수백만 로우) fact table의 경우에는 엄청난 개수의 row가 존재한다(페타바이트).
fact table의 column 개수는 보통 100개 이상이지만 질의시 4~5개 의 column에만 접근한다.
한편 대부분의 OLTP 데이터베이스에서 저장소는 row 지향 방식으로 데이터를 배치한다.

칼럼 지향 저장소의 기본 개념은 간단하다. 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼별로 모든 값을 함께 저장한다.
칼럼 지향 저장소 배치는 각 칼럼 파일에 포함된 로우가 모두 같은 순서인 점에 의존한다.

#### 칼럼 압축

칼럼 값에서 비슷한 값이 반복해서 나오는 경향이 있음. 비트맵 및 런 랭쓰 부호화를 통한 압축, 이외에도 다양한 압축 방법이 있다.

#### 칼럼 저장소의 순서 정렬

row가 저장되는 순서가 반드시 중요하지는 않다. 다만 각 칼럼을 독립적으로 정렬할 수는 없다.
질의에 따라 키를 잘 설정하자. 한편 정렬 작업을 통해 칼럼에 연속적인 값이 나타나게 되므로 칼럼 압축 측면에서 도움이 된다.

#### 다양한 순서 정렬
다양한 질의를 위해 다양한 방식으로 정렬해 저장하는 방식. 하나의 장비가 고장 나도 데이터를 잃지 않기 위해 데이터를 복제하는 작업이 필요하므로 복제 데이터를 서로 다른 방식으로 저장하므로써 다양한 질의에 대응 가능하다.

#### 칼럼 지향 저장소에 쓰기

칼럼 지향 저장소, 압축, 정렬은 모두 쓰기를 어렵게 한다는 단점이 있다. 값의 갱신을 원할 경우 압축을 풀고 고치고 다시 압축하는 과정을 거쳐야한다.
이에 대한 해결책으로는 앞선 LSM에서 소개했던 인메모리 저장소에서 정렬된 구조체에 추가하고 추후 디스크에 쓰는 방법이 있다.

#### 집계: 데이터 큐브와 구체화 뷰

구체화 집계(materialized aggregate) => 데이터 웨어하우스의 질의는 보통 SQL에 COUNT, SUM, AVG, MIN, MAX 같은 집계 함수를 포함한다. => 이에 대한 캐시를 미리 만들어 놓자 => 구체화 뷰 (materialized view)
데이터 큐브(data cube) 혹은 OLAP 큐브 : 구체화 뷰의 한 종류, 외래키를 축으로 하여  원하는 값을 n차원으로 미리 저장한다.

=> 유연성은 없는 방법이지만 빠르다. 특정 질의에 대한 성능 향상을 위해 사용
